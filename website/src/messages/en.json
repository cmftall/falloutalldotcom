{
  "navigation": {
    "home": "Home",
    "work": "Results",
    "contact": "Hire Me"
  },
  "common": {
    "toggleTheme": "Toggle theme"
  },
        "hero": {
          "headline": "I deliver measurable ROI through pragmatic data architecture",
          "subheadline": "Business value-focused Data Architect | 8+ years reducing errors, cutting costs, and building teams across Banking, Telecom & Tech",
          "primaryCta": "View Case Studies",
          "secondaryCta": "Book Discovery Call",
          "credential": "Data Architect • Paris, France & Montreal, Canada",
          "projectOutcomes": "Up to 30% error reduction • €130K+ annual savings • 100+ pipelines built",
          "technicalInnovation": "Pragmatic solutions that teams can actually support, delivering measurable business outcomes",
          "credibilityIndicators": [
            "Led teams of 7+ engineers",
            "€130K+ annual savings through data quality innovation",
            "100+ production pipelines built and maintained",
            "Multi-industry expertise (Banking, Telecom, Technology)",
            "8+ years enterprise transformation leadership"
          ],
          "professionalPositioning": "I focus on business value - delivering ROI through pragmatic architecture that prioritizes what matters: reducing costs, improving quality, and building sustainable teams"
        },
  "expertise": {
    "title": "Expertise",
    "subtitle": "Core competencies organized by proficiency and depth of experience",
    "tierDescription": {
      "core": "Areas of deep expertise through 6-8+ years of professional practice",
      "advanced": "Strong proficiency with 4-5 years of hands-on experience",
      "working": "Practical working knowledge and ongoing development"
    },
    "technicalDepth": "Advanced technical skills and methodologies in data architecture",
    "architecturalThinking": "Strategic data architecture planning and enterprise-scale solutions",
    "methodologies": [
      "DataOps automation frameworks",
      "Micro-services data architecture", 
      "Zero-downtime migration strategies",
      "Advanced ML model deployment",
      "Multi-cloud data governance"
    ],
    "tiers": {
      "core": {
        "title": "Core Expertise",
        "description": "Deep expertise proven through extensive professional practice",
        "categories": {
          "dataEngineering": {
            "name": "Data Engineering", 
            "skills": "Python, Scala, SQL, Apache Airflow, Terraform",
            "proficiency": "Expert",
            "yearsExperience": 8,
            "methodologies": ["ETL/ELT pipeline design", "Data quality frameworks", "Infrastructure as Code"]
          },
          "databases": {
            "name": "Databases",
            "skills": "PostgreSQL, Oracle, Cassandra, MongoDB, Delta Lake",
            "proficiency": "Expert",
            "yearsExperience": 7,
            "methodologies": ["Database optimization", "Data modeling", "Performance tuning"]
          },
          "cloudPlatforms": {
            "name": "Cloud Data Architecture",
            "skills": "Azure, AWS, Databricks, Snowflake, Apache Spark",
            "proficiency": "Expert",
            "yearsExperience": 6,
            "methodologies": ["Multi-cloud architecture", "Cloud-native data processing", "Serverless data pipelines"]
          }
        }
      },
      "advanced": {
        "title": "Advanced Skills",
        "description": "Strong proficiency with proven delivery experience",
        "categories": {
          "machineLearning": {
            "name": "Machine Learning",
            "skills": "Scikit-Learn, TensorFlow, Pandas, NumPy, MLflow",
            "proficiency": "Advanced",
            "yearsExperience": 5,
            "methodologies": ["ML model deployment", "Feature engineering", "Model monitoring"]
          },
          "devops": {
            "name": "DevOps & DataOps",
            "skills": "GitHub Actions, Azure DevOps, Docker, Kubernetes, DataOps",
            "proficiency": "Advanced",
            "yearsExperience": 5,
            "methodologies": ["CI/CD pipelines", "Container orchestration", "DataOps automation"]
          },
          "visualization": {
            "name": "Data Visualization",
            "skills": "Tableau, Power BI, Jupyter, Streamlit, Plotly",
            "proficiency": "Advanced",
            "yearsExperience": 4,
            "methodologies": ["Interactive dashboards", "Data storytelling", "Real-time analytics"]
          }
        }
      }
    }
  },
  "education": {
    "title": "Education",
    "subtitle": "Mathematical sciences foundation with Big Data specialization",
    "degrees": {
      "aims-masters-bigdata": {
        "degree": "Master in Mathematical Sciences - Big Data",
        "institution": "AIMS",
        "year": "2018"
      },
      "ucad-masters-applied": {
        "degree": "Master in Applied Mathematics",
        "institution": "Cheikh Anta Diop University",
        "year": "2016"
      }
    }
  },
        "contact": {
          "title": "Ready to Deliver Measurable ROI?",
          "subtitle": "Let's discuss how I can help reduce your costs and improve data quality",
          "value": "I help enterprises reduce costs and improve data quality through pragmatic architecture that teams can actually support.",
          "service1": "Architecture audits & advisory",
          "service2": "Data quality framework training",
          "service3": "Short-term consulting projects",
          "primaryCta": "Book Discovery Call",
          "rates": "€700-1800/day",
          "email": "Email",
          "location": "Location"
        },
  "footer": {
    "copyright": "© 2025 Fallou TALL. All rights reserved.",
    "builtWith": "Built with Next.js and Tailwind CSS"
  },
        "work": {
          "title": "Real Results, Real Impact",
          "subtitle": "How I've delivered measurable business value across large enterprise companies",
          "businessImpact": "Clear evidence of business value and ROI through measurable outcomes",
          "technicalInnovation": "Technical innovation combined with measurable business impact",
          "sections": {
            "keyAchievements": "Key Achievements",
            "businessImpact": "Business Impact",
            "technicalInnovation": "Technical Innovation",
            "technologies": "Technologies & Tools"
          },
          "projects": {
      "sopra-steria-data-architect": {
        "company": "Sopra Steria",
        "role": "Data Architect Transverse - DCOE",
        "duration": "11/2025 - Present",
        "location": "France",
        "focusArea": "Transverse data architecture and center of excellence leadership",
        "description": "Leading data architecture center of excellence, driving cross-functional data platform strategy, enterprise data governance frameworks, and technical leadership across multiple projects.",
        "keyAchievements": [
          "Leading data architecture center of excellence",
          "Cross-functional data platform strategy",
          "Enterprise data governance frameworks",
          "Technical leadership across multiple projects"
        ],
        "technologies": ["Azure", "AWS", "Databricks", "Python", "Snowflake", "Spark", "SQL", "Terraform"],
        "businessImpact": [
          {
            "metricName": "Architecture Standardization",
            "percentage": 100,
            "description": "Establishing enterprise-wide data architecture standards and best practices"
          }
        ],
        "technicalInnovation": [
          "Center of Excellence frameworks",
          "Enterprise data architecture patterns",
          "Cross-functional governance models",
          "Technical leadership methodologies"
        ],
        "industry": "Technology & Consulting"
      },
      "onepoint-expert-data": {
        "company": "Onepoint",
        "role": "Consultant Expert Data",
        "duration": "09/2024 - 10/2025",
        "location": "Canada et France",
        "durationNote": "Part-time 09/2024-04/2025 alongside BNC, then full contract until 10/2025",
        "focusArea": "Modern and scalable data platform implementation",
        "description": "Delivering technical, organizational, and governance audits for enterprise data platforms across Canada and France. Designing modern, scalable architectures for large enterprise companies.",
        "keyAchievements": [
          "Technical audits, data architecture design",
          "ETL/ELT pipeline development", 
          "DataOps implementation",
          "Monitoring solutions and data security",
          "Training delivery"
        ],
        "technologies": ["Azure", "AWS", "Databricks", "Python", "Snowflake", "Spark", "SQL", "Github Actions"],
        "businessImpact": [
          {
            "metricName": "Client Satisfaction",
            "percentage": 95,
            "description": "Achieved high client satisfaction with data platform implementations"
          },
          {
            "metricName": "Platform Performance", 
            "percentage": 40,
            "description": "Achieved up to 40% performance improvement across client data platforms"
          }
        ],
        "technicalInnovation": [
          "Modern data platform architecture patterns",
          "DataOps automation frameworks",
          "Multi-cloud data governance solutions",
          "Security-first data architecture design"
        ],
        "industry": "Consulting & Technology"
      },
      "bnc-analytical-foundation": {
        "company": "Banque Nationale du Canada",
        "role": "Lead Data Engineer", 
        "duration": "11/2021 - 04/2025",
        "location": "Canada",
        "focusArea": "Analytical foundation implementation",
        "description": "Leading team of 7 engineers building robust analytical pipelines with innovative PySpark QA frameworks.",
        "keyAchievements": [
          "Led team of 7 analysts and data engineers",
          "Developed innovative PySpark library achieving up to 30% error reduction",
          "Increased process efficiency by up to 25%",
          "Automated QA tests reducing test time by up to 40%"
        ],
        "technologies": ["Azure", "AWS", "Databricks", "Python", "Snowflake", "Spark", "SQL", "Terraform"],
        "businessImpact": [
          {
            "metricName": "Error Reduction",
            "percentage": 30,
            "description": "Achieved up to 30% reduction in data processing errors through innovative PySpark framework"
          },
          {
            "metricName": "Efficiency Improvement",
            "percentage": 25, 
            "description": "Achieved up to 25% increase in data processing efficiency across analytical pipelines"
          },
          {
            "metricName": "Testing Speed",
            "percentage": 40,
            "description": "Achieved up to 40% faster QA testing through automation"
          }
        ],
        "technicalInnovation": [
          "Innovative PySpark QA framework",
          "Automated testing pipelines",
          "Advanced data quality monitoring",
          "Scalable analytical architecture"
        ],
        "industry": "Banking & Financial Services"
      },
      "orange-hadoop-migration": {
        "company": "Orange Côte d'Ivoire",
        "role": "Lead Data Engineer",
        "duration": "09/2020 - 08/2021", 
        "location": "Côte d'Ivoire",
        "focusArea": "Hadoop cluster migration and update",
        "description": "Led zero-downtime migration of data workflows to new Hadoop cluster. Developed productivity tools and orchestrated complex data pipelines.",
        "keyAchievements": [
          "Supervised data workflow migration",
          "Migrated Flume/Pig/Spark1/Sqoop to Spark2",
          "Developed Spark library achieving up to 20% productivity increase"
        ],
        "technologies": ["Hadoop", "Scala", "Spark", "Oracle"],
        "businessImpact": [
          {
            "metricName": "Productivity Improvement",
            "percentage": 20,
            "description": "Achieved up to 20% increase in data engineering productivity through custom Spark library"
          },
          {
            "metricName": "Migration Success",
            "percentage": 100,
            "description": "Successfully completed zero-downtime migration of critical data workflows"
          }
        ],
        "technicalInnovation": [
          "Zero-downtime migration strategy",
          "Custom Spark productivity library", 
          "Advanced workflow orchestration",
          "Legacy system modernization"
        ],
        "industry": "Telecommunications"
      },
      "orange-qoe-management": {
        "company": "Orange Sénégal",
        "role": "Senior Data Engineer & Data Scientist",
        "duration": "06/2019 - 08/2020",
        "location": "Sénégal", 
        "focusArea": "Customer Experience Management",
        "description": "Developed ML models for customer experience management and QoE prediction.",
        "keyAchievements": [
          "Developed ML models predicting customer QoE achieving up to 15% satisfaction improvement",
          "Automated processes reducing processing time by up to 30%",
          "NPS-QoE correlation analysis with Tableau dashboards"
        ],
        "technologies": ["Hadoop", "Scala", "Spark", "SQL Server", "Tableau", "Python", "Scikit-Learn", "Flask"],
        "businessImpact": [
          {
            "metricName": "Customer Satisfaction",
            "percentage": 15,
            "description": "Achieved up to 15% improvement in customer satisfaction through QoE prediction models"
          },
          {
            "metricName": "Processing Efficiency",
            "percentage": 30,
            "description": "Achieved up to 30% reduction in processing time through automation"
          }
        ],
        "technicalInnovation": [
          "Advanced ML models for QoE prediction",
          "Automated data processing pipelines",
          "Real-time customer analytics",
          "Advanced correlation analysis"
        ],
        "industry": "Telecommunications"
      },
      "orange-data-monetization": {
        "company": "Orange Sénégal",
        "role": "Data Engineer & Data Scientist",
        "duration": "10/2018 - 04/2019",
        "location": "Sénégal",
        "focusArea": "Digital data monetization platform", 
        "description": "Micro-services architecture with Kubernetes/Kafka/Cassandra/Spark/Node.js, location modeling from CDR data, population movement prediction with SparkML.",
        "keyAchievements": [
          "Micro-services architecture with Kubernetes/Kafka/Cassandra/Spark/Node.js",
          "Location modeling from CDR data",
          "Population movement prediction with SparkML"
        ],
        "technologies": ["Cassandra", "Kafka", "Kubernetes", "Scala", "Spark"],
        "businessImpact": [
          {
            "metricName": "Platform Scalability",
            "percentage": 300,
            "description": "Achieved 3x scalability with micro-services architecture supporting high-volume data processing"
          },
          {
            "metricName": "Data Monetization",
            "percentage": 25,
            "description": "Enabled new revenue streams through data-driven insights"
          }
        ],
        "technicalInnovation": [
          "Micro-services data architecture",
          "Real-time location analytics",
          "Population movement prediction models",
          "Advanced CDR data processing"
        ],
        "industry": "Telecommunications"
      }
    }
  },
  "stats": {
    "yearsExperience": "Years Experience",
    "technologiesMastered": "Technologies Mastered",
    "enterpriseProjects": "Enterprise Projects"
  },
  "common": {
    "loading": "Loading...",
    "error": "An error occurred",
    "retry": "Retry",
    "close": "Close",
    "open": "Open",
    "readMore": "Read More",
    "viewProject": "View Project",
    "learnMore": "Learn More",
    "pageNotFound": "Page Not Found",
    "pageNotFoundDescription": "Sorry, the page you're looking for doesn't exist or has been moved.",
    "goHome": "Go Home",
    "goBack": "Go Back",
    "tryThesePages": "Or try one of these pages:"
  }
}
