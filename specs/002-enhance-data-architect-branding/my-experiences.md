# üìä FALLOU TALL - COMPLETE PROFESSIONAL EXPERIENCE

**8 Years of Data Engineering & Architecture**  
**‚Ç¨360K+ in Proven Savings | 4 Countries**

---

## üéØ **CAREER SUMMARY**

**Career Progression:**
```
2018: Data Engineer (Entry Level)
  ‚Üì
2019: Senior Data Engineer & Data Scientist
  ‚Üì
2020: Lead Data Engineer
  ‚Üì
2021: Lead Data Engineer (Major Bank)
  ‚Üì
2022: Expert Data Architect
  ‚Üì
2025: Lead Data Architect (Center of Excellence)
```

**Total Impact:**

- **100+ data pipelines** built and maintained
- **4 enterprise clients** consulted
- **7+ engineers** led and trained

---

## üíº **COMPLETE WORK HISTORY**

### **1. SOPRA STERIA** üè¢
**Current Role: Transverse Data Architect - Center of Excellence (DCoE)**  
**Duration:** November 2025 - Present (Current)  
**Location:** Courbevoie, France  

#### **What I'm Building:**
As a Transverse Data Architect in Sopra Steria's Data Center of Excellence, I architect data solutions for clients across multiple industries: Banking, Insurance, Public Sector, Telecom, Media, Gaming, Industry and Services. This is a strategic role where I support delivery teams from prospecting through pre-sales to solution delivery.

#### **Key Responsibilities:**
- **Elaborate optimized data architectures:** Design analytical platforms, real-time systems, and IoT data solutions
- **Design data ingestion strategies:** Implement real-time, asynchronous, and intermediation tools for data collection
- **Client engagement:** Participate in workshops for design and consulting, provide technical leadership
- **Pre-sales support:** Analyze RFPs, craft technical responses (functional, technical, software architecture), deliver client presentations
- **Solution delivery:** Lead development teams and participate actively in solution implementation
- **Ecosystem collaboration:** Work with market-leading editors and hyperscalers to deliver best-in-class solutions

#### **Focus Areas:**
- Data architecture and platform design
- Data governance frameworks
- Data catalog and referential management
- Data quality frameworks and standards
- AI industrialization and ML Ops

#### **Technologies:**
Azure, AWS, Databricks, Python, Snowflake, Spark, SQL, Java, Scala, MDM, ETL, ESB, API Management, Terraform

#### **Current Status:**
- Role starts November 2025
- Available for consulting projects until November 2025
- Working across 8+ industry sectors
- Supporting dozens of projects simultaneously

#### **Why This Matters:**
This role represents a shift from individual project delivery to enterprise-wide architecture standards. Instead of building one system, I'm designing frameworks and patterns that will be reused across hundreds of projects. My work influences:
- **Pre-sales:** Technical architecture decisions that win contracts
- **Delivery:** Standardized patterns that accelerate project delivery
- **Practice Development:** Building reusable assets for the entire Data Center of Excellence
- **Client Success:** Multi-sector expertise means I can spot patterns across industries

#### **The Scope:**
- **8+ industry sectors:** Banking, Insurance, Public Sector, Telecom, Media, Gaming, Industry, Services
- **Full project lifecycle:** From initial prospecting to solution delivery
- **Strategic impact:** Architecture decisions affect entire client organizations
- **Team support:** Enabling delivery teams with best practices and standards

#### **Honest Assessment:**
Too early for concrete metrics (role starts November 2025), but the scope is significant - my architecture work will impact dozens of projects, hundreds of engineers, and millions of end users across Sopra Steria's client portfolio. This is a Center of Excellence role, meaning I'm building reusable assets and standards, not just delivering individual projects.

---

### **2. ONEPOINT** üåê
**Role: Expert Data (Consulting)**  
**Duration:** September 2024 - October 2025 (14 months)  
**Location:** Paris, France & Montreal, Canada  
**Employment:** Part-time (09/2024-04/2025) alongside National Bank, then full-time (05/2025-10/2025)

#### **The Business:**
Consulting on enterprise data platforms for major clients across banking, telecom, and technology sectors.

#### **What I Did:**
- **Technical Audits:** Assessed existing data infrastructure, identified issues
- **Architecture Design:** Designed scalable cloud data platforms
- **Implementation Advisory:** Guided teams on ETL/ELT pipelines, DataOps
- **Training:** Trained client teams on sustainable data practices

#### **Real Business Results:**
- **40% performance improvement** in client data processing systems through optimized architecture
- **‚Ç¨50K+ savings identified** through audit recommendations

#### **Technologies:**
Azure, AWS, Databricks, Snowflake, Python, Spark, SQL, Github Actions

#### **Why This Succeeded:**
I didn't just deliver reports - I rolled up my sleeves and helped teams implement solutions. Clients renewed because they saw actual improvements, not just PowerPoint slides.

---

### **3. NATIONAL BANK OF CANADA** üè¶
**Role: Lead Data Engineer**  
**Duration:** November 2021 - April 2025 (3.5 years)  
**Location:** Montreal, Canada  
**Team Size:** Led team of 7 engineers (2 junior, 2 mid-level, 3 senior)

#### **The Challenge:**
Canada's 6th largest bank ($400B+ assets) had failing data systems costing them money daily. The bank needed a modern analytical foundation to support critical business decisions, but existing systems were fragmented:
- Data errors were constant (50+ per month)
- Pipelines were breaking regularly
- Testing took 2-5 days per release
- The engineering team was overwhelmed
- No centralized data quality standards
- Legacy systems couldn't support modern analytics needs

#### **What I Built:**
Led a team of 7 engineers to build a modern data warehouse (data lake + data warehouse) that became the analytical foundation for Canada's 6th largest bank. The platform enabled critical business decisions across Marketing, Cards & Payments, Fraud Detection, and Executive reporting used by board-level leadership.

**Platform Capabilities:**
- **Marketing Analytics:** Customer acquisition strategy (CAC tracking, segmentation, Next Best Action)
- **Real-time Fraud Detection:** Fraud analytics and detection systems
- **Cards & Payment Analytics:** Transaction analysis and insights
- **Executive Reporting:** Board-level reporting and dashboards
- **AI/ML Support:** Foundation for machine learning models

#### **The Technical Architecture:**
- **Initial Platform:** Azure with Snowflake and Databricks
- **Migration:** Successfully migrated to AWS with zero downtime
- **Architecture Pattern:** Hybrid (Data Lake + Data Warehouse)
- **Data Modeling:** 20+ dimensional models (Star schemas + One Big Table patterns)
- **Processing Volume:** 10-100 TB total data, 200GB-1TB daily processing
- **Source Systems:** 20+ source systems integrated
- **Historical Tracking:** SCD Type 2 for historical data management
- **Domains:** Customer & Marketing Analytics (bank-wide usage)

#### **The Numbers (All Verifiable):**

**Error Reduction - ‚Ç¨65K+ Annual Savings:**
- **Before:** 50+ data errors per month in production pipelines
- **After:** ~35 errors per month  
- **Result:** 30% reduction in data processing errors
- **Calculation:** Each error = 4-8 hours √ó 2-3 people to fix
- **Impact:** 180-240 hours/month saved
- **Annual Savings:** **‚Ç¨65K-130K/year** in reduced support costs

**Processing Speed - ‚Ç¨65K+ Annual Value:**
- **Improvement:** 25% faster data processing
- **Impact:** 3 hours/day saved per engineer √ó 7 engineers = 21 hours/day
- **Capacity Gain:** 125GB+ more daily capacity enabled additional data sources
- **Business Value:** More timely analytics, faster decision-making
- **Annual Value:** **‚Ç¨65K+/year** in productivity gains

**Testing Speed - Release Acceleration:**
- **Before:** 2-5 days for QA testing per release
- **After:** 1.8 days average
- **Result:** 40% faster release cycles
- **Impact:** 10-20 deployments/month √ó 1.25 days saved = 19-25 days/month additional capacity
- **Business Value:** Faster time-to-market for new analytics capabilities
- **Annual Value:** **‚Ç¨20K+/year** in reduced testing overhead

**Total Documented Savings: ‚Ç¨150K-215K/year**

#### **The PySpark QA Framework - Bank-Wide Standard:**
The data quality framework I developed wasn't just a tool - it became a bank-wide standard:

**Adoption Journey:**
- **Started:** Optional framework for our team
- **Proven:** 30% error reduction demonstrated value
- **Adopted:** Became mandatory standard across data engineering
- **Expanded:** Used in 80+ of 100+ production pipelines
- **Open-Sourced:** Internally open-sourced, multiple teams contributed improvements
- **Still Running:** Framework maintained and extended after I left

**Technical Capabilities:**
- **8 Validation Types:** Schema validation, business rules, statistical anomalies, data quality checks, reconciliation, automated alerts, completeness checks, referential integrity
- **Automated Testing:** Reduced manual QA effort by 40%
- **Real-time Monitoring:** Automated alerts for data quality issues
- **Reusable Components:** Modular design enabled adoption across teams

**Cross-Departmental Impact:**
- **Marketing:** Used for customer segmentation and CAC analytics
- **Wealth Management:** Data quality for portfolio analytics
- **Cards & Payments:** Transaction data validation
- **Fraud Detection:** Data quality for ML models
- **10-20+ Teams:** Adopted framework across departments

#### **Collaboration with CDO (Chief Data Officer):**
Worked directly with the CDO to:
- **Define:** Data quality dimensions and metrics
- **Standardize:** Cross-departmental data quality standards
- **Operationalize:** Implement governance frameworks
- **Enable:** Consistent data quality practices across the bank

#### **Technologies & Tools:**
**Cloud Platforms:** Azure (initial), AWS (migrated), Snowflake, Databricks  
**Languages:** Python, PySpark, Spark, SQL  
**Infrastructure:** Terraform (Infrastructure as Code)  
**Data Modeling:** dbt (data transformation)  
**Processing:** 100+ production pipelines, real-time and batch processing

#### **Team Development & Leadership:**
- **1 Engineer ‚Üí Team Lead:** My direct successor was promoted from within the team
- **2 Engineers ‚Üí Senior Roles:** Promoted to senior positions during my tenure
- **7 Engineers Trained:** All team members trained on modern cloud data architecture
- **Knowledge Transfer:** Comprehensive documentation and training programs
- **Sustainable Success:** Team continued improving the framework after I left

#### **Multi-Cloud Migration Achievement:**
Successfully migrated the entire platform from Azure to AWS with:
- **Zero Downtime:** No service interruption
- **Data Integrity:** 100% data consistency maintained
- **Performance Maintained:** No degradation in processing speed
- **Team Trained:** All engineers adapted to new infrastructure seamlessly

#### **Business Impact Beyond Numbers:**
- **Critical Reporting:** Platform powers executive dashboards used by board-level leadership
- **Customer Acquisition:** Marketing's Next Best Action strategy relies on this platform
- **Fraud Prevention:** Real-time fraud detection processes millions of transactions
- **Compliance:** Meets regulatory requirements for data governance
- **Strategic Foundation:** Enables AI/ML initiatives across the bank

#### **Why This Was My Best Work:**
This project combined technical excellence with lasting organizational change:

1. **Technical Achievement:** Built a modern data platform serving Canada's 6th largest bank
2. **Framework Innovation:** Created a quality framework that became a bank standard
3. **Team Development:** Trained and promoted engineers, built sustainable practices
4. **Organizational Impact:** Influenced data quality standards across 10-20+ teams
5. **Long-Term Value:** Framework still running, still saving money, still being improved
6. **Zero-Downtime Migration:** Successfully moved entire platform between cloud providers
7. **Business Enablement:** Platform supports critical business decisions at the highest levels

The ultimate proof of success: The framework I built is still being used, extended, and improved by the teams I trained. That's sustainable impact - not just delivering a project, but building capabilities that outlive your presence.

---

### **4. ORANGE C√îTE D'IVOIRE** üì±
**Role: Lead Data Engineer**  
**Duration:** September 2020 - August 2021 (1 year)  
**Location:** Abidjan, C√¥te d'Ivoire  
**Company Scale:** 14M+ customers, Africa's largest Orange subsidiary

#### **The Challenge:**
Orange needed to migrate 50+ critical data workflows to a new Hadoop cluster while serving 14 million customers 24/7. One hour of downtime = revenue loss + customer complaints + regulatory issues. The systems were old and using legacy technologies.

#### **What I Did:**
Led the zero-downtime migration of all data systems. Modernized workflows from legacy tools (Flume, Pig, Spark 1.x, Sqoop) to modern Spark 2.x while keeping everything running.

#### **The Results:**

**Zero Downtime:**
- **50+ critical workflows migrated**
- **14M+ customers unaffected**
- **100% uptime maintained** throughout migration
- **0 incidents** during the entire project
- **Completed ahead of schedule**

**Team Productivity - ‚Ç¨130K+ Value:**
- **20% productivity increase** for data engineering team
- **Custom Spark library** I developed became standard tooling
- **Legacy modernization:** 5-year-old systems updated without disruption

**Business Continuity:**
- **Billing systems:** Never went down
- **Customer data:** Continuously available
- **Regulatory compliance:** Maintained throughout
- **Revenue impact:** Zero (no downtime)

#### **Technologies:**
Hadoop, Scala, Spark (1.x ‚Üí 2.x migration), Oracle, Python

#### **Why This Was Hard:**
It's not just technical - it's risk management. One mistake affects 14 million people. One hour of downtime could cost millions. The migration strategy had to be bulletproof.

#### **Migration Strategy:**
- **Parallel Running:** Old and new systems running simultaneously
- **Incremental Cutover:** One workflow at a time, with rollback plans
- **Automated Validation:** Real-time data reconciliation
- **24/7 Monitoring:** Instant alerts for any issues

#### **What Made This Special:**
Zero-downtime migrations for systems this critical are rare. Most companies plan for maintenance windows. We didn't have that luxury - Orange C√¥te d'Ivoire doesn't sleep.

---

### **5. ORANGE S√âN√âGAL** üá∏üá≥
**Role: Senior Data Engineer & Data Scientist**  
**Duration:** June 2019 - August 2020 (1 year, 2 months)  
**Location:** Dakar, S√©n√©gal  
**Focus:** Customer Experience Management

#### **The Business Problem:**
Orange was losing customers but didn't know why. Customer satisfaction was declining, but they had no way to predict which customers were at risk or what was causing poor experiences.

#### **What I Built:**
Machine Learning models to predict customer experience (QoE - Quality of Experience) and automated analytics pipelines to identify problems before customers complained.

#### **The Results:**

**Customer Satisfaction:**
- **15% improvement** in customer satisfaction scores
- **Predictive Models:** Could identify at-risk customers before they churned
- **Proactive Intervention:** Fixed issues before customers noticed

**Processing Efficiency:**
- **30% reduction** in analytics processing time through automation
- **Real-time Dashboards:** NPS-QoE correlation analysis in Tableau
- **Automated Alerts:** Executives notified of issues immediately

#### **Technologies:**
Hadoop, Scala, Spark, SQL Server, Tableau, Python, Scikit-Learn, Flask

#### **What This Demonstrated:**
This was my first major Data Science role (vs pure engineering). Showed I could not only build systems, but also extract business insights from data using ML.

#### **The ML Pipeline:**
- **Data Sources:** Call records, network metrics, customer feedback
- **Models:** Regression for QoE prediction, classification for churn risk
- **Deployment:** Real-time scoring via Flask API
- **Monitoring:** Model performance tracked in Tableau

#### **Business Impact:**
15% customer satisfaction improvement in telecom = millions in retained revenue. Customers who don't churn = ongoing monthly revenue.

---

### **6. ORANGE S√âN√âGAL** üó∫Ô∏è
**Role: Data Engineer & Data Scientist**  
**Duration:** October 2018 - April 2019 (6 months)  
**Location:** Dakar, S√©n√©gal  
**Focus:** Data Monetization Platform

#### **The Business Opportunity:**
Orange had valuable location data from millions of customers. They wanted to monetize this data (with privacy protections) by selling insights to businesses - population movement patterns, traffic analysis, urban planning data.

#### **What I Built:**
Scalable microservices platform for location analytics and population movement prediction. Modern architecture using Kubernetes, Kafka, Cassandra, and Spark.

#### **The Technical Achievement:**
- **Microservices Architecture:** Kubernetes orchestration for scalability
- **Real-time Processing:** Kafka for streaming CDR (Call Detail Records) data
- **Location Modeling:** Algorithms to process CDR data at scale
- **Movement Prediction:** SparkML models predicting population flows

#### **Technologies:**
Cassandra, Kafka, Kubernetes, Scala, Spark, Node.js

#### **Why This Mattered:**
This was my first project (first 6 months of career), but I was working with modern, scalable architecture from day one. Most engineers start with legacy systems - I started with the future.

#### **What I Learned:**
- **Distributed Systems:** Handling millions of events per day
- **Real-time Processing:** Kafka streaming vs batch processing
- **Privacy:** Building data products that respect user privacy
- **Scalability:** Architecture that handles 10x growth

#### **Business Model:**
Data products sold to:
- **Urban Planners:** Population movement for infrastructure planning
- **Retail:** Foot traffic analysis for store placement
- **Transport:** Commute patterns for route optimization
- **Government:** Emergency response and public health

---

## üìà **CAREER PROGRESSION ANALYSIS**

### **Technical Evolution:**
```
2018: Microservices, Kafka, Spark (Entry level)
  ‚Üì
2019: + Machine Learning, Flask APIs (Senior)
  ‚Üì
2020: + Zero-downtime migrations, Legacy modernization (Lead)
  ‚Üì
2021: + Team leadership, Quality frameworks, dbt (Lead at major bank)
  ‚Üì
2024: + Architecture design, Multi-cloud, Consulting (Architect)
  ‚Üì
2025: + Center of Excellence, Architecture standards (Lead Architect)
```

### **Business Impact Evolution:**
```
2018: Built systems (foundational)
  ‚Üì
2019: Improved customer satisfaction 15% (business outcomes)
  ‚Üì
2020: Zero downtime for 14M users (risk mitigation)
  ‚Üì
2021: Saved ‚Ç¨130K+/year (direct cost reduction)
  ‚Üì
2025: Building frameworks for dozens of projects (strategic impact)
```

### **Leadership Evolution:**
```
2018: Individual contributor
  ‚Üì
2019: Senior IC, mentoring juniors
  ‚Üì
2020: Lead engineer, project leadership
  ‚Üì
2021: Team lead (7 engineers), hiring, training
  ‚Üì
2024: Consulting expert, client advisory
  ‚Üì
2025: Center of Excellence lead, practice development
```

---

## üí∞ **TOTAL BUSINESS VALUE DELIVERED**

### **Documented Financial Impact:**
- **National Bank of Canada:** ‚Ç¨130K-215K/year saved
- **Orange Migrations:** ‚Ç¨130K+ value (productivity + risk mitigation)
- **Orange QoE:** 15% satisfaction = millions in retention
- **Total:** **‚Ç¨360K+ documented annual value**

### **Operational Impact:**
- **14M+ customers** served without downtime
- **150+ data pipelines** built and maintained
- **80+ pipelines** using my quality framework
- **7 engineers** trained and developed
- **4 enterprise clients** consulted
- **3 zero-incident projects** delivered

### **Technical Innovation:**
- **PySpark QA Framework:** Company standard at National Bank
- **Spark Library:** Team standard at Orange
- **Zero-downtime Strategy:** Deployed across 50+ systems
- **ML Models:** 15% customer satisfaction improvement

---

## üéØ **WHAT MAKES ME DIFFERENT**

### **1. Business Focus, Not Tech Focus**
I don't build systems because they're cool - I build them because they save money or make money. Every project above has clear business metrics.

### **2. From Code to Strategy**
Started writing Spark jobs in 2018. Now designing architecture for entire consulting practices. Progression: Engineer ‚Üí Lead ‚Üí Architect ‚Üí Strategic Lead.

### **3. Team Builder, Not Solo Hero**
National Bank team kept improving my framework after I left. That's success - when your work outlives your presence.

### **4. Risk Manager**
Zero-downtime migration for 14M users isn't luck - it's planning, testing, and contingency plans. I deliver without drama.

### **5. Consultant Mindset**
Clients keep me because I make their problems go away.

---

## üåç **GEOGRAPHIC EXPERIENCE**

### **Countries Worked:**
- üá´üá∑ **France** (Paris) - Current (Sopra Steria, Onepoint)
- üá®üá¶ **Canada** (Montreal) - 3.5 years (National Bank, Onepoint)
- üá®üáÆ **C√¥te d'Ivoire** (Abidjan) - 1 year (Orange)
- üá∏üá≥ **S√©n√©gal** (Dakar) - 1.5 years (Orange)

### **Language Skills:**
- French (Native)
- English (Fluent)
- Working across multiple time zones and cultures

---

## üõ†Ô∏è **COMPLETE TECHNOLOGY STACK**

### **Cloud Platforms:**
- **Azure** (4 years) - Primary at National Bank
- **AWS** (3 years) - Multi-cloud projects, National Bank, Onepoint

### **Data Processing:**
- **Apache Spark** (8 years) - Core technology since 2018
- **PySpark** (8 years) - Built frameworks, 100+ pipelines
- **Scala** (4 years) - Early Orange projects
- **Databricks** (5 years) - Primary platform

### **Databases:**
- **Snowflake** (4 years) - National Bank, consulting
- **PostgreSQL, Oracle** (5 years) - Multiple projects
- **Cassandra** (2 years) - Orange microservices
- **Delta Lake** (3 years) - Lakehouse architectures

### **Data Engineering:**
- **dbt** (2 years) - Data modeling at National Bank
- **Apache Airflow** (4 years) - Orchestration
- **Kafka** (3 years) - Real-time streaming
- **ETL/ELT** (8 years) - Core skill

### **DevOps & Infrastructure:**
- **Terraform** (3 years) - Infrastructure as Code
- **Docker** (4 years) - Containerization
- **GitHub Actions** (4 years) - CI/CD pipelines

### **Machine Learning:**
- **Scikit-Learn, TensorFlow** (3 years) - Orange projects
- **MLflow** (2 years) - Model tracking
- **SparkML** (3 years) - Large-scale ML

### **Data Visualization:**
- **Tableau** (3 years) - Orange dashboards
- **Power BI** (2 years) - National Bank reporting

---

## üìä **BY THE NUMBERS**

### **Experience:**
- **8 years** in data (2018-2025)
- **6 companies** (Orange 2x, National Bank, Onepoint, Sopra Steria, + consulting)
- **4 countries** (France, Canada, C√¥te d'Ivoire, S√©n√©gal)
- **6 major projects** documented above

### **Impact:**
- **‚Ç¨360K+** documented annual value delivered
- **14M+ users** served without downtime
- **100+ pipelines** built
- **7 engineers** led and trained
- **4 enterprise clients** consulted

### **Technical:**
- **20+ technologies** mastered
- **3 cloud platforms** (Azure, AWS, GCP)
- **3 major frameworks** created (PySpark QA, Spark Library, Architecture Patterns)

---

## üéì **EDUCATION**

### **Master in Mathematical Sciences - Big Data**
**Institution:** AIMS (African Institute for Mathematical Sciences)  
**Year:** 2018  
**Focus:** Advanced mathematics, machine learning, big data

### **Master in Applied Mathematics**
**Institution:** Cheikh Anta Diop University  
**Year:** 2016  
**Focus:** Mathematical modeling, statistics, Operation Research

---

## ‚úÖ **WHAT THIS ALL MEANS**

### **For Employers:**
You're hiring someone who has:
- Built systems from scratch (Orange 2018)
- Led teams successfully (National Bank 2021-2025)
- Delivered measurable business value (‚Ç¨360K+ documented)
- Worked at scale (14M+ users, 150+ pipelines)
- Progressed steadily (Engineer ‚Üí Architect in 8 years)

### **For Clients:**
You're getting someone who:
- Delivers results, not presentations 
- Understands business, not just tech (every project has ROI)
- Manages risk (zero-downtime for 14M users)
- Builds lasting solutions (National Bank still using my framework)
- Works at any scale (startup to major bank)

### **For The Honest:**
I've documented everything here:
- When metrics are strong, I show them (‚Ç¨130K+ at National Bank)
- When projects are new, I say so (Sopra Steria - too early)
- When impact is indirect, I explain it (team productivity, client retention)
- When credit is shared, I acknowledge it (led team of 7, not solo)

---

## üöÄ **WHAT'S NEXT**

### **Current Focus (2025):**
- **Architecture Design:** Multi-sector data architecture patterns for Banking, Insurance, Public Sector, Telecom, Media, Gaming, Industry and Services
- **Pre-Sales Support:** Technical responses, architecture presentations, RFP analysis
- **Governance Frameworks:** Data quality, data catalog, referential management standards
- **AI Industrialization:** ML Ops and AI deployment methodologies
- **Practice Development:** Building reusable architecture assets for Sopra Steria's Data Center of Excellence

### **Career Goals:**
Continue the progression from tactical execution to strategic architecture. Want to influence how enterprises think about data architecture, not just implement their plans.

### **Available For:**
- Short-term consulting projects (2-6 months)
- Architecture advisory
- Data quality framework implementation
- Zero-downtime migrations
- Team training and development

**Rates:** ‚Ç¨700-1800/day depending on project scope  
**Location:** Paris, France (willing to travel, remote possible)  
**Contact:** cmftall@gmail.com | [LinkedIn](https://www.linkedin.com/in/cmftall)

---

**Last Updated:** October 2025  
**Document Status:** Complete professional history

